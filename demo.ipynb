{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bhavy\\Desktop\\Career\\Internship\\Clovertex\\GenAI Internship Assignment\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All libraries imported successfully\n",
            "üìç Working directory: c:\\Users\\bhavy\\Desktop\\Career\\Internship\\Clovertex\\GenAI Internship Assignment\\submissions\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, Optional, List, TypedDict, Annotated\n",
        "import google.generativeai as genai\n",
        "from langgraph.graph import StateGraph, END\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Set your Gemini API key here\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully\")\n",
        "print(f\"üìç Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ WorkflowState defined\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "LANGGRAPH STATE DEFINITION\n",
        "Defines the state object passed between agents in the workflow\n",
        "\"\"\"\n",
        "\n",
        "class WorkflowState(TypedDict):\n",
        "    \"\"\"State object for LangGraph workflow\"\"\"\n",
        "    # Input parameters\n",
        "    work_type: str\n",
        "    description: str\n",
        "    priority: int\n",
        "    request_date: str\n",
        "    \n",
        "    # Agent 1 output\n",
        "    work_id: str\n",
        "    \n",
        "    # Agent 2 output\n",
        "    work_request: Dict[str, Any]\n",
        "    required_specialty: str\n",
        "    alternate_specialty: Optional[str]\n",
        "    \n",
        "    # Agent 3 output\n",
        "    primary_candidates: List[Dict[str, Any]]\n",
        "    alternate_candidates: List[Dict[str, Any]]\n",
        "    \n",
        "    # Agent 4 output\n",
        "    best_candidate: Dict[str, Any]\n",
        "    all_candidates: List[Dict[str, Any]]\n",
        "    \n",
        "    # Agent 5 output\n",
        "    final_result: Dict[str, Any]\n",
        "\n",
        "print(\"‚úÖ WorkflowState defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DatabaseManager class defined with enhanced features\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "DATABASE MANAGER CLASS\n",
        "Handles all SQLite database operations with enhanced error handling\n",
        "\"\"\"\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"Handles all database operations for the work allocation system\"\"\"\n",
        "    \n",
        "    def __init__(self, db_path: str = \"radiology.db\"):\n",
        "        self.db_path = db_path\n",
        "        self.conn = None\n",
        "    \n",
        "    def connect(self):\n",
        "        \"\"\"Establish database connection with foreign key enforcement\"\"\"\n",
        "        self.conn = sqlite3.connect(self.db_path)\n",
        "        self.conn.row_factory = sqlite3.Row\n",
        "        # Enable foreign key constraints\n",
        "        self.conn.execute(\"PRAGMA foreign_keys = ON\")\n",
        "        return self.conn\n",
        "    \n",
        "    def close(self):\n",
        "        \"\"\"Close database connection\"\"\"\n",
        "        if self.conn:\n",
        "            self.conn.close()\n",
        "    \n",
        "    def setup_database(self, data_folder: str = \"data/\"):\n",
        "        \"\"\"Create tables with foreign keys and import CSV data\"\"\"\n",
        "        self.connect()\n",
        "        cursor = self.conn.cursor()\n",
        "        \n",
        "        print(\"üîß Setting up database with enhanced schema...\")\n",
        "        \n",
        "        # Create work_requests table with foreign keys\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS work_requests (\n",
        "                work_id TEXT PRIMARY KEY,\n",
        "                work_type TEXT NOT NULL,\n",
        "                description TEXT,\n",
        "                priority INTEGER CHECK(priority >= 1 AND priority <= 5),\n",
        "                timestamp DATETIME,\n",
        "                status TEXT DEFAULT 'pending',\n",
        "                assigned_to TEXT,\n",
        "                FOREIGN KEY (assigned_to) REFERENCES resources(resource_id)\n",
        "                    ON DELETE SET NULL\n",
        "            )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Create resources table\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS resources (\n",
        "                resource_id TEXT PRIMARY KEY,\n",
        "                name TEXT NOT NULL,\n",
        "                specialty TEXT NOT NULL,\n",
        "                skill_level INTEGER CHECK(skill_level >= 1 AND skill_level <= 5),\n",
        "                total_cases_handled INTEGER DEFAULT 0\n",
        "            )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Create resource_calendar table\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS resource_calendar (\n",
        "                calendar_id TEXT PRIMARY KEY,\n",
        "                resource_id TEXT NOT NULL,\n",
        "                date DATE NOT NULL,\n",
        "                available_from TIME NOT NULL,\n",
        "                available_to TIME NOT NULL,\n",
        "                current_workload INTEGER DEFAULT 0,\n",
        "                FOREIGN KEY (resource_id) REFERENCES resources(resource_id)\n",
        "                    ON DELETE CASCADE\n",
        "            )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Create specialty_mapping table\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS specialty_mapping (\n",
        "                work_type TEXT PRIMARY KEY,\n",
        "                required_specialty TEXT NOT NULL,\n",
        "                alternate_specialty TEXT\n",
        "            )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Create indexes\n",
        "        cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_resources_specialty ON resources(specialty)\")\n",
        "        cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_calendar_resource ON resource_calendar(resource_id)\")\n",
        "        cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_work_status ON work_requests(status)\")\n",
        "        \n",
        "        self.conn.commit()\n",
        "        \n",
        "        # Import CSV data\n",
        "        resources_df = pd.read_csv(os.path.join(data_folder, \"resources.csv\"))\n",
        "        resources_df.to_sql(\"resources\", self.conn, if_exists=\"replace\", index=False)\n",
        "        print(f\" ‚úì Imported {len(resources_df)} resources\")\n",
        "        \n",
        "        calendar_df = pd.read_csv(os.path.join(data_folder, \"resource_calendar.csv\"))\n",
        "        calendar_df.to_sql(\"resource_calendar\", self.conn, if_exists=\"replace\", index=False)\n",
        "        print(f\" ‚úì Imported {len(calendar_df)} calendar entries\")\n",
        "        \n",
        "        specialty_df = pd.read_csv(os.path.join(data_folder, \"specialty_mapping.csv\"))\n",
        "        specialty_df.to_sql(\"specialty_mapping\", self.conn, if_exists=\"replace\", index=False)\n",
        "        print(f\" ‚úì Imported {len(specialty_df)} specialty mappings\")\n",
        "        \n",
        "        work_df = pd.read_csv(os.path.join(data_folder, \"work_requests.csv\"))\n",
        "        work_df.to_sql(\"work_requests\", self.conn, if_exists=\"replace\", index=False)\n",
        "        print(f\" ‚úì Imported {len(work_df)} work requests\")\n",
        "        \n",
        "        self.conn.commit()\n",
        "        print(\"‚úÖ Database setup complete with foreign key constraints!\")\n",
        "    \n",
        "    def add_work_request(self, work_type: str, description: str, priority: int, custom_date: str = None) -> str:\n",
        "        \"\"\"Add a new work request with input validation\"\"\"\n",
        "        # Validate priority\n",
        "        if not isinstance(priority, int) or not 1 <= priority <= 5:\n",
        "            raise ValueError(\"Priority must be integer between 1 and 5\")\n",
        "        \n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) as count FROM work_requests\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        work_id = f\"W{str(count + 1).zfill(3)}\"\n",
        "        \n",
        "        if custom_date:\n",
        "            timestamp = f\"{custom_date} {datetime.now().strftime('%H:%M:%S')}\"\n",
        "        else:\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        \n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO work_requests (work_id, work_type, description, priority, timestamp, status)\n",
        "            VALUES (?, ?, ?, ?, ?, 'pending')\n",
        "        \"\"\", (work_id, work_type, description, priority, timestamp))\n",
        "        self.conn.commit()\n",
        "        return work_id\n",
        "    \n",
        "    def get_work_request(self, work_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Get work request details by ID\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM work_requests WHERE work_id = ?\", (work_id,))\n",
        "        row = cursor.fetchone()\n",
        "        return dict(row) if row else None\n",
        "    \n",
        "    def get_specialty_mapping(self, work_type: str) -> Optional[Dict[str, str]]:\n",
        "        \"\"\"Get required and alternate specialties for a work type\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM specialty_mapping WHERE work_type = ?\", (work_type,))\n",
        "        row = cursor.fetchone()\n",
        "        return dict(row) if row else None\n",
        "    \n",
        "    def find_resources_by_specialty(self, specialty: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Find all resources with given specialty\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"SELECT * FROM resources WHERE specialty = ?\", (specialty,))\n",
        "        return [dict(row) for row in cursor.fetchall()]\n",
        "    \n",
        "    def get_resource_availability(self, resource_id: str, date: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Get availability info for a resource on a specific date\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT * FROM resource_calendar \n",
        "            WHERE resource_id = ? AND date = ?\n",
        "        \"\"\", (resource_id, date))\n",
        "        row = cursor.fetchone()\n",
        "        return dict(row) if row else None\n",
        "    \n",
        "    def assign_work(self, work_id: str, resource_id: str) -> bool:\n",
        "        \"\"\"Enhanced assignment with transaction management\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        \n",
        "        try:\n",
        "            cursor.execute(\"BEGIN TRANSACTION\")\n",
        "            \n",
        "            # Validate work not already assigned\n",
        "            work = self.get_work_request(work_id)\n",
        "            if not work:\n",
        "                raise ValueError(f\"Work request {work_id} not found\")\n",
        "            if work['status'] == 'assigned':\n",
        "                raise ValueError(f\"Work {work_id} already assigned to {work['assigned_to']}\")\n",
        "            \n",
        "            # Update work_requests\n",
        "            cursor.execute('''\n",
        "                UPDATE work_requests \n",
        "                SET assigned_to = ?, status = 'assigned'\n",
        "                WHERE work_id = ?\n",
        "            ''', (resource_id, work_id))\n",
        "            \n",
        "            # INCREMENT total_cases_handled (FIX #1)\n",
        "            cursor.execute('''\n",
        "                UPDATE resources \n",
        "                SET total_cases_handled = total_cases_handled + 1\n",
        "                WHERE resource_id = ?\n",
        "            ''', (resource_id,))\n",
        "            \n",
        "            self.conn.commit()\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.conn.rollback()\n",
        "            print(f\"‚ùå Assignment failed: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def update_workload(self, resource_id: str, date: str, increment: int = 1):\n",
        "        \"\"\"Update resource workload for a specific date\"\"\"\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            UPDATE resource_calendar\n",
        "            SET current_workload = current_workload + ?\n",
        "            WHERE resource_id = ? AND date = ?\n",
        "        \"\"\", (increment, resource_id, date))\n",
        "        self.conn.commit()\n",
        "\n",
        "print(\"‚úÖ DatabaseManager class defined with enhanced features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ResourceScorer class defined\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "RESOURCE SCORER\n",
        "Transparent 100-point weighted scoring system\n",
        "\"\"\"\n",
        "\n",
        "class ResourceScorer:\n",
        "    \"\"\"Calculate scores for resource candidates based on multiple factors\"\"\"\n",
        "    \n",
        "    WEIGHTS = {\n",
        "        'skill_level': 25,\n",
        "        'experience': 20,\n",
        "        'availability': 30,\n",
        "        'workload': 15,\n",
        "        'priority_bonus': 10\n",
        "    }\n",
        "    \n",
        "    def calculate_score(self, resource: Dict[str, Any], availability: Dict[str, Any],\n",
        "                       work_request: Dict[str, Any], role_match_type: str) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate comprehensive score for a resource candidate\"\"\"\n",
        "        \n",
        "        if role_match_type == 'none':\n",
        "            return {'total_score': 0, 'breakdown': {}, 'reason': 'No specialty match'}\n",
        "        \n",
        "        # Calculate individual scores\n",
        "        skill_score = (resource['skill_level'] / 5.0) * self.WEIGHTS['skill_level']\n",
        "        experience_score = min(resource['total_cases_handled'] / 20.0, self.WEIGHTS['experience'])\n",
        "        \n",
        "        # Availability score\n",
        "        available_from = datetime.strptime(availability['available_from'], '%H:%M:%S').time()\n",
        "        available_to = datetime.strptime(availability['available_to'], '%H:%M:%S').time()\n",
        "        from_minutes = available_from.hour * 60 + available_from.minute\n",
        "        to_minutes = available_to.hour * 60 + available_to.minute\n",
        "        hours_available = (to_minutes - from_minutes) / 60.0\n",
        "        availability_score = min(hours_available / 8.0, 1.0) * self.WEIGHTS['availability']\n",
        "        \n",
        "        # Workload score (lower is better)\n",
        "        workload_score = max(0, self.WEIGHTS['workload'] - (availability['current_workload'] * 1.5))\n",
        "        \n",
        "        # Priority bonus\n",
        "        if work_request['priority'] >= 4 and availability['current_workload'] <= 2:\n",
        "            priority_bonus = self.WEIGHTS['priority_bonus']\n",
        "        else:\n",
        "            priority_bonus = (work_request['priority'] / 5.0) * self.WEIGHTS['priority_bonus']\n",
        "        \n",
        "        # Calculate total\n",
        "        total_score = skill_score + experience_score + availability_score + workload_score + priority_bonus\n",
        "        \n",
        "        # Apply multiplier for alternate specialty\n",
        "        multiplier = 0.8 if role_match_type == 'alternate' else 1.0\n",
        "        total_score *= multiplier\n",
        "        \n",
        "        return {\n",
        "            'total_score': round(total_score, 2),\n",
        "            'breakdown': {\n",
        "                'skill_score': round(skill_score, 2),\n",
        "                'experience_score': round(experience_score, 2),\n",
        "                'availability_score': round(availability_score, 2),\n",
        "                'workload_score': round(workload_score, 2),\n",
        "                'priority_bonus': round(priority_bonus, 2),\n",
        "                'role_match_type': role_match_type,\n",
        "                'multiplier': multiplier\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def rank_candidates(self, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Sort candidates by total score (descending)\"\"\"\n",
        "        return sorted(candidates, key=lambda x: x['score']['total_score'], reverse=True)\n",
        "\n",
        "print(\"‚úÖ ResourceScorer class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All LangGraph agent nodes defined\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "LANGGRAPH AGENT NODE FUNCTIONS\n",
        "Each function represents one agent in the workflow\n",
        "\"\"\"\n",
        "\n",
        "# Agent 1: Add Work Request\n",
        "def add_work_node(state: WorkflowState, db: DatabaseManager) -> WorkflowState:\n",
        "    \"\"\"Agent 1: Add work request to database\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"[AGENT 1: AddWorkAgent] Processing new work request\")\n",
        "    print('='*60)\n",
        "    print(f\" Work Type: {state['work_type']}\")\n",
        "    print(f\" Description: {state['description']}\")\n",
        "    print(f\" Priority: {state['priority']}/5\")\n",
        "    print(f\" Request Date: {state['request_date']}\")\n",
        "    \n",
        "    work_id = db.add_work_request(\n",
        "        state['work_type'], \n",
        "        state['description'], \n",
        "        state['priority'], \n",
        "        state['request_date']\n",
        "    )\n",
        "    print(f\" ‚úÖ Work request created: {work_id}\")\n",
        "    \n",
        "    state['work_id'] = work_id\n",
        "    return state\n",
        "\n",
        "# Agent 2: Analyze Work\n",
        "def analyze_work_node(state: WorkflowState, db: DatabaseManager) -> WorkflowState:\n",
        "    \"\"\"Agent 2: Analyze work request and determine required specialty\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[AGENT 2: WorkAnalyzerAgent] Analyzing {state['work_id']}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    work_request = db.get_work_request(state['work_id'])\n",
        "    if not work_request:\n",
        "        raise ValueError(f\"Work request {state['work_id']} not found\")\n",
        "    \n",
        "    print(f\" Work Type: {work_request['work_type']}\")\n",
        "    print(f\" Priority: {work_request['priority']}/5\")\n",
        "    \n",
        "    specialty_map = db.get_specialty_mapping(work_request['work_type'])\n",
        "    if not specialty_map:\n",
        "        raise ValueError(f\"No specialty mapping for {work_request['work_type']}\")\n",
        "    \n",
        "    required_specialty = specialty_map['required_specialty']\n",
        "    alternate_specialty = specialty_map.get('alternate_specialty')\n",
        "    \n",
        "    print(f\" Required Specialty: {required_specialty}\")\n",
        "    if alternate_specialty:\n",
        "        print(f\" Alternate Specialty: {alternate_specialty}\")\n",
        "    print(f\" ‚úÖ Analysis complete\")\n",
        "    \n",
        "    state['work_request'] = work_request\n",
        "    state['required_specialty'] = required_specialty\n",
        "    state['alternate_specialty'] = alternate_specialty\n",
        "    return state\n",
        "\n",
        "# Agent 3: Find Resources\n",
        "def find_resources_node(state: WorkflowState, db: DatabaseManager) -> WorkflowState:\n",
        "    \"\"\"Agent 3: Find resources matching required specialty\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"[AGENT 3: ResourceFinderAgent] Finding matching resources\")\n",
        "    print('='*60)\n",
        "    \n",
        "    primary_candidates = db.find_resources_by_specialty(state['required_specialty'])\n",
        "    print(f\" Primary ({state['required_specialty']}): {len(primary_candidates)} found\")\n",
        "    for candidate in primary_candidates:\n",
        "        print(f\" ‚Ä¢ {candidate['name']} (Skill: {candidate['skill_level']}/5)\")\n",
        "    \n",
        "    alternate_candidates = []\n",
        "    if state.get('alternate_specialty'):\n",
        "        alternate_candidates = db.find_resources_by_specialty(state['alternate_specialty'])\n",
        "        print(f\" Alternate ({state['alternate_specialty']}): {len(alternate_candidates)} found\")\n",
        "        for candidate in alternate_candidates:\n",
        "            print(f\" ‚Ä¢ {candidate['name']} (Skill: {candidate['skill_level']}/5)\")\n",
        "    \n",
        "    print(f\" ‚úÖ Total: {len(primary_candidates) + len(alternate_candidates)} candidates\")\n",
        "    \n",
        "    state['primary_candidates'] = primary_candidates\n",
        "    state['alternate_candidates'] = alternate_candidates\n",
        "    return state\n",
        "\n",
        "# Agent 4: Score and Select\n",
        "def score_candidates_node(state: WorkflowState, db: DatabaseManager) -> WorkflowState:\n",
        "    \"\"\"Agent 4: Score candidates and select best match\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"[AGENT 4: AvailabilityCheckerAgent] Scoring candidates\")\n",
        "    print('='*60)\n",
        "    \n",
        "    scorer = ResourceScorer()\n",
        "    all_scored = []\n",
        "    request_date = state['work_request']['timestamp'].split()[0]\n",
        "    print(f\" Request Date: {request_date}\")\n",
        "    \n",
        "    # Score primary candidates\n",
        "    print(f\"\\n Scoring primary candidates...\")\n",
        "    for resource in state['primary_candidates']:\n",
        "        availability = db.get_resource_availability(resource['resource_id'], request_date)\n",
        "        if availability:\n",
        "            score = scorer.calculate_score(resource, availability, state['work_request'], 'exact')\n",
        "            all_scored.append({\n",
        "                'resource': resource,\n",
        "                'availability': availability,\n",
        "                'score': score\n",
        "            })\n",
        "            print(f\" ‚Ä¢ {resource['name']}: {score['total_score']}/100\")\n",
        "    \n",
        "    # Score alternate candidates\n",
        "    if state.get('alternate_candidates'):\n",
        "        print(f\"\\n Scoring alternate candidates...\")\n",
        "        for resource in state['alternate_candidates']:\n",
        "            availability = db.get_resource_availability(resource['resource_id'], request_date)\n",
        "            if availability:\n",
        "                score = scorer.calculate_score(resource, availability, state['work_request'], 'alternate')\n",
        "                all_scored.append({\n",
        "                    'resource': resource,\n",
        "                    'availability': availability,\n",
        "                    'score': score\n",
        "                })\n",
        "                print(f\" ‚Ä¢ {resource['name']}: {score['total_score']}/100 (alternate)\")\n",
        "    \n",
        "    # Rank candidates\n",
        "    ranked = scorer.rank_candidates(all_scored)\n",
        "    if not ranked:\n",
        "        raise ValueError(\"No suitable candidates found\")\n",
        "    \n",
        "    best_candidate = ranked[0]\n",
        "    print(f\"\\n üìä Best match: {best_candidate['resource']['name']}\")\n",
        "    print(f\" üìä Score: {best_candidate['score']['total_score']}/100\")\n",
        "    print(f\" ‚úÖ Selection complete\")\n",
        "    \n",
        "    state['best_candidate'] = best_candidate\n",
        "    state['all_candidates'] = ranked\n",
        "    return state\n",
        "\n",
        "# Agent 5: Assign and Explain\n",
        "def assign_work_node(state: WorkflowState, db: DatabaseManager, gemini_api_key: str) -> WorkflowState:\n",
        "    \"\"\"Agent 5: Finalize assignment and generate LLM explanation\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"[AGENT 5: AssignmentAgent] Finalizing assignment\")\n",
        "    print('='*60)\n",
        "    \n",
        "    resource = state['best_candidate']['resource']\n",
        "    availability = state['best_candidate']['availability']\n",
        "    score = state['best_candidate']['score']\n",
        "    \n",
        "    # Update database with enhanced logging (FIX #2)\n",
        "    print(f\" Updating database...\")\n",
        "    try:\n",
        "        db.assign_work(state['work_id'], resource['resource_id'])\n",
        "        db.update_workload(resource['resource_id'], availability['date'], 1)\n",
        "        \n",
        "        print(f\" ‚úÖ Updates completed:\")\n",
        "        print(f\"    - Status: pending ‚Üí assigned\")\n",
        "        print(f\"    - Assigned to: {resource['resource_id']}\")\n",
        "        print(f\"    - Total cases: +1\")\n",
        "        print(f\"    - Workload: +1\")\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå Database update failed: {e}\")\n",
        "        raise\n",
        "    \n",
        "    # Generate LLM explanation with enhanced prompt (FIX #3)\n",
        "    print(f\" Generating AI explanation...\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    \n",
        "    prompt = f\"\"\"You are an expert medical staffing coordinator AI. Explain this assignment decision professionally.\n",
        "\n",
        "ASSIGNMENT CONTEXT:\n",
        "- Work: {state['work_request']['work_type']}\n",
        "- Description: {state['work_request']['description']}\n",
        "- Priority: {state['work_request']['priority']}/5 {\"(URGENT)\" if state['work_request']['priority'] >= 4 else \"(Routine)\"}\n",
        "\n",
        "SELECTED RADIOLOGIST:\n",
        "- Name: {resource['name']}\n",
        "- Specialty: {resource['specialty']} (Match: {score['breakdown']['role_match_type']})\n",
        "- Skill Level: {resource['skill_level']}/5\n",
        "- Experience: {resource['total_cases_handled']} cases completed\n",
        "- Availability: {availability['available_from']}-{availability['available_to']}\n",
        "- Current Workload: {availability['current_workload']} active cases\n",
        "\n",
        "DECISION SCORE: {score['total_score']}/100\n",
        "\n",
        "Generate 2-3 sentences explaining why this radiologist is optimal for this case, highlighting key strengths.\n",
        "Professional medical tone. No markdown formatting.\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        explanation = response.text.strip()\n",
        "    except Exception:\n",
        "        # Fallback if API fails\n",
        "        explanation = f\"{resource['name']} was assigned based on {resource['specialty']} specialty, skill level {resource['skill_level']}/5, and {resource['total_cases_handled']} cases experience with current workload of {availability['current_workload']} cases.\"\n",
        "    \n",
        "    print(f\" ‚úÖ Explanation generated\")\n",
        "    \n",
        "    print(f\"\\n {'='*60}\")\n",
        "    print(f\" üéØ ASSIGNMENT COMPLETE\")\n",
        "    print(f\" {'='*60}\")\n",
        "    print(f\" Work ID: {state['work_id']}\")\n",
        "    print(f\" Assigned To: {resource['name']}\")\n",
        "    print(f\" Score: {score['total_score']}/100\")\n",
        "    \n",
        "    state['final_result'] = {\n",
        "        'work_id': state['work_id'],\n",
        "        'assigned_to': resource['resource_id'],\n",
        "        'resource_name': resource['name'],\n",
        "        'score': score,\n",
        "        'explanation': explanation\n",
        "    }\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"‚úÖ All LangGraph agent nodes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LangGraph workflow orchestrator defined\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "LANGGRAPH WORKFLOW CREATION\n",
        "Creates the actual LangGraph state machine with proper orchestration\n",
        "\"\"\"\n",
        "\n",
        "def create_workflow(db: DatabaseManager, gemini_api_key: str) -> Any:\n",
        "    \"\"\"Create LangGraph workflow with 5 agents\"\"\"\n",
        "    \n",
        "    # Create StateGraph\n",
        "    workflow = StateGraph(WorkflowState)\n",
        "    \n",
        "    # Add nodes (agents)\n",
        "    workflow.add_node(\"add_work\", lambda state: add_work_node(state, db))\n",
        "    workflow.add_node(\"analyze\", lambda state: analyze_work_node(state, db))\n",
        "    workflow.add_node(\"find_resources\", lambda state: find_resources_node(state, db))\n",
        "    workflow.add_node(\"score\", lambda state: score_candidates_node(state, db))\n",
        "    workflow.add_node(\"assign\", lambda state: assign_work_node(state, db, gemini_api_key))\n",
        "    \n",
        "    # Add edges (workflow order)\n",
        "    workflow.add_edge(\"add_work\", \"analyze\")\n",
        "    workflow.add_edge(\"analyze\", \"find_resources\")\n",
        "    workflow.add_edge(\"find_resources\", \"score\")\n",
        "    workflow.add_edge(\"score\", \"assign\")\n",
        "    workflow.add_edge(\"assign\", END)\n",
        "    \n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"add_work\")\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "def run_workflow(db: DatabaseManager, gemini_api_key: str, \n",
        "                work_type: str, description: str, priority: int, \n",
        "                request_date: str = \"2024-11-10\") -> Dict[str, Any]:\n",
        "    \"\"\"Execute complete LangGraph workflow\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üöÄ STARTING LANGGRAPH WORKFLOW\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # Create workflow\n",
        "        app = create_workflow(db, gemini_api_key)\n",
        "        \n",
        "        # Initialize state\n",
        "        initial_state: WorkflowState = {\n",
        "            'work_type': work_type,\n",
        "            'description': description,\n",
        "            'priority': priority,\n",
        "            'request_date': request_date,\n",
        "            'work_id': '',\n",
        "            'work_request': {},\n",
        "            'required_specialty': '',\n",
        "            'alternate_specialty': None,\n",
        "            'primary_candidates': [],\n",
        "            'alternate_candidates': [],\n",
        "            'best_candidate': {},\n",
        "            'all_candidates': [],\n",
        "            'final_result': {}\n",
        "        }\n",
        "        \n",
        "        # Run workflow\n",
        "        final_state = app.invoke(initial_state)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"‚úÖ LANGGRAPH WORKFLOW COMPLETED SUCCESSFULLY\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        return {\n",
        "            'success': True,\n",
        "            'result': final_state['final_result'],\n",
        "            'all_candidates': final_state['all_candidates']\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Workflow failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return {'success': False, 'error': str(e)}\n",
        "\n",
        "print(\"‚úÖ LangGraph workflow orchestrator defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Setting up database with enhanced schema...\n",
            " ‚úì Imported 15 resources\n",
            " ‚úì Imported 45 calendar entries\n",
            " ‚úì Imported 8 specialty mappings\n",
            " ‚úì Imported 22 work requests\n",
            "‚úÖ Database setup complete with foreign key constraints!\n",
            "\n",
            "üéØ System ready with true LangGraph orchestration!\n"
          ]
        }
      ],
      "source": [
        "# Initialize SYSTEM\n",
        "db = DatabaseManager(\"radiology.db\")\n",
        "db.setup_database(\"data/\")\n",
        "\n",
        "print(\"\\nüéØ System ready with true LangGraph orchestration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Scenarios (Using LangGraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ STARTING LANGGRAPH WORKFLOW\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "[AGENT 1: AddWorkAgent] Processing new work request\n",
            "============================================================\n",
            " Work Type: MRI_Brain\n",
            " Description: Suspected acute stroke - immediate MRI evaluation required\n",
            " Priority: 5/5\n",
            " Request Date: 2024-11-10\n",
            " ‚úÖ Work request created: W023\n",
            "\n",
            "============================================================\n",
            "[AGENT 2: WorkAnalyzerAgent] Analyzing W023\n",
            "============================================================\n",
            " Work Type: MRI_Brain\n",
            " Priority: 5/5\n",
            " Required Specialty: Neurologist\n",
            " Alternate Specialty: General_Radiologist\n",
            " ‚úÖ Analysis complete\n",
            "\n",
            "============================================================\n",
            "[AGENT 3: ResourceFinderAgent] Finding matching resources\n",
            "============================================================\n",
            " Primary (Neurologist): 4 found\n",
            " ‚Ä¢ Dr. Sarah Chen (Skill: 5/5)\n",
            " ‚Ä¢ Dr. James Wilson (Skill: 2/5)\n",
            " ‚Ä¢ Dr. Maria Garcia (Skill: 4/5)\n",
            " ‚Ä¢ Dr. Kevin Park (Skill: 4/5)\n",
            " Alternate (General_Radiologist): 4 found\n",
            " ‚Ä¢ Dr. John Smith (Skill: 4/5)\n",
            " ‚Ä¢ Dr. Emily Brown (Skill: 3/5)\n",
            " ‚Ä¢ Dr. Michael Davis (Skill: 3/5)\n",
            " ‚Ä¢ Dr. Alex Johnson (Skill: 4/5)\n",
            " ‚úÖ Total: 8 candidates\n",
            "\n",
            "============================================================\n",
            "[AGENT 4: AvailabilityCheckerAgent] Scoring candidates\n",
            "============================================================\n",
            " Request Date: 2024-11-10\n",
            "\n",
            " Scoring primary candidates...\n",
            " ‚Ä¢ Dr. Sarah Chen: 92.75/100\n",
            " ‚Ä¢ Dr. James Wilson: 66.65/100\n",
            " ‚Ä¢ Dr. Maria Garcia: 66.05/100\n",
            " ‚Ä¢ Dr. Kevin Park: 76.95/100\n",
            "\n",
            " Scoring alternate candidates...\n",
            " ‚Ä¢ Dr. John Smith: 61.12/100 (alternate)\n",
            " ‚Ä¢ Dr. Emily Brown: 48.6/100 (alternate)\n",
            " ‚Ä¢ Dr. Michael Davis: 46.68/100 (alternate)\n",
            " ‚Ä¢ Dr. Alex Johnson: 48.88/100 (alternate)\n",
            "\n",
            " üìä Best match: Dr. Sarah Chen\n",
            " üìä Score: 92.75/100\n",
            " ‚úÖ Selection complete\n",
            "\n",
            "============================================================\n",
            "[AGENT 5: AssignmentAgent] Finalizing assignment\n",
            "============================================================\n",
            " Updating database...\n",
            " ‚úÖ Updates completed:\n",
            "    - Status: pending ‚Üí assigned\n",
            "    - Assigned to: R005\n",
            "    - Total cases: +1\n",
            "    - Workload: +1\n",
            " Generating AI explanation...\n",
            " ‚úÖ Explanation generated\n",
            "\n",
            " ============================================================\n",
            " üéØ ASSIGNMENT COMPLETE\n",
            " ============================================================\n",
            " Work ID: W023\n",
            " Assigned To: Dr. Sarah Chen\n",
            " Score: 92.75/100\n",
            "\n",
            "================================================================================\n",
            "‚úÖ LANGGRAPH WORKFLOW COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "SCENARIO 1 RESULTS\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Assignment: Dr. Sarah Chen (R005)\n",
            "\n",
            "üìä Score Breakdown:\n",
            "   skill_score: 25.0\n",
            "   experience_score: 17.25\n",
            "   availability_score: 30.0\n",
            "   workload_score: 10.5\n",
            "   priority_bonus: 10.0\n",
            "   role_match_type: exact\n",
            "   multiplier: 1.0\n",
            "\n",
            "   TOTAL SCORE: 92.75/100\n",
            "\n",
            "üí° AI Explanation:\n",
            "   Dr. Sarah Chen was assigned based on Neurologist specialty, skill level 5/5, and 345 cases experience with current workload of 3 cases.\n",
            "\n",
            "üèÜ Top 3 Candidates:\n",
            "   1. Dr. Sarah Chen: 92.75/100\n",
            "   2. Dr. Kevin Park: 76.95/100\n",
            "   3. Dr. James Wilson: 66.65/100\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Scenario 1: Urgent Neurological Case (Priority 5)\n",
        "Demonstrates: LangGraph orchestration, Priority handling, Exact specialty match\n",
        "\"\"\"\n",
        "\n",
        "result1 = run_workflow(\n",
        "    db=db,\n",
        "    gemini_api_key=GEMINI_API_KEY,\n",
        "    work_type=\"MRI_Brain\",\n",
        "    description=\"Suspected acute stroke - immediate MRI evaluation required\",\n",
        "    priority=5\n",
        ")\n",
        "\n",
        "if result1['success']:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 1 RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    res = result1['result']\n",
        "    print(f\"\\n‚úÖ Assignment: {res['resource_name']} ({res['assigned_to']})\")\n",
        "    print(f\"\\nüìä Score Breakdown:\")\n",
        "    for key, value in res['score']['breakdown'].items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "    print(f\"\\n   TOTAL SCORE: {res['score']['total_score']}/100\")\n",
        "    \n",
        "    print(f\"\\nüí° AI Explanation:\")\n",
        "    print(f\"   {res['explanation']}\")\n",
        "    \n",
        "    print(f\"\\nüèÜ Top 3 Candidates:\")\n",
        "    for i, candidate in enumerate(result1['all_candidates'][:3], 1):\n",
        "        print(f\"   {i}. {candidate['resource']['name']}: {candidate['score']['total_score']}/100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ STARTING LANGGRAPH WORKFLOW\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "[AGENT 1: AddWorkAgent] Processing new work request\n",
            "============================================================\n",
            " Work Type: X_Ray_Chest\n",
            " Description: Annual checkup - routine chest X-ray screening\n",
            " Priority: 2/5\n",
            " Request Date: 2024-11-11\n",
            " ‚úÖ Work request created: W024\n",
            "\n",
            "============================================================\n",
            "[AGENT 2: WorkAnalyzerAgent] Analyzing W024\n",
            "============================================================\n",
            " Work Type: X_Ray_Chest\n",
            " Priority: 2/5\n",
            " Required Specialty: General_Radiologist\n",
            " ‚úÖ Analysis complete\n",
            "\n",
            "============================================================\n",
            "[AGENT 3: ResourceFinderAgent] Finding matching resources\n",
            "============================================================\n",
            " Primary (General_Radiologist): 4 found\n",
            " ‚Ä¢ Dr. John Smith (Skill: 4/5)\n",
            " ‚Ä¢ Dr. Emily Brown (Skill: 3/5)\n",
            " ‚Ä¢ Dr. Michael Davis (Skill: 3/5)\n",
            " ‚Ä¢ Dr. Alex Johnson (Skill: 4/5)\n",
            " ‚úÖ Total: 4 candidates\n",
            "\n",
            "============================================================\n",
            "[AGENT 4: AvailabilityCheckerAgent] Scoring candidates\n",
            "============================================================\n",
            " Request Date: 2024-11-11\n",
            "\n",
            " Scoring primary candidates...\n",
            " ‚Ä¢ Dr. John Smith: 74.9/100\n",
            " ‚Ä¢ Dr. Emily Brown: 45.75/100\n",
            " ‚Ä¢ Dr. Michael Davis: 60.6/100\n",
            " ‚Ä¢ Dr. Alex Johnson: 53.6/100\n",
            "\n",
            " üìä Best match: Dr. John Smith\n",
            " üìä Score: 74.9/100\n",
            " ‚úÖ Selection complete\n",
            "\n",
            "============================================================\n",
            "[AGENT 5: AssignmentAgent] Finalizing assignment\n",
            "============================================================\n",
            " Updating database...\n",
            " ‚úÖ Updates completed:\n",
            "    - Status: pending ‚Üí assigned\n",
            "    - Assigned to: R001\n",
            "    - Total cases: +1\n",
            "    - Workload: +1\n",
            " Generating AI explanation...\n",
            " ‚úÖ Explanation generated\n",
            "\n",
            " ============================================================\n",
            " üéØ ASSIGNMENT COMPLETE\n",
            " ============================================================\n",
            " Work ID: W024\n",
            " Assigned To: Dr. John Smith\n",
            " Score: 74.9/100\n",
            "\n",
            "================================================================================\n",
            "‚úÖ LANGGRAPH WORKFLOW COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "SCENARIO 2 RESULTS\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Assignment: Dr. John Smith (R001)\n",
            "\n",
            "üìä Score: 74.9/100\n",
            "\n",
            "üí° AI Explanation:\n",
            "   Dr. John Smith was assigned based on General_Radiologist specialty, skill level 4/5, and 178 cases experience with current workload of 2 cases.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Scenario 2: Routine Chest X-Ray (Priority 2)\n",
        "Demonstrates: Workload balancing, Lower priority handling\n",
        "\"\"\"\n",
        "\n",
        "result2 = run_workflow(\n",
        "    db=db,\n",
        "    gemini_api_key=GEMINI_API_KEY,\n",
        "    work_type=\"X_Ray_Chest\",\n",
        "    description=\"Annual checkup - routine chest X-ray screening\",\n",
        "    priority=2,\n",
        "    request_date=\"2024-11-11\"\n",
        ")\n",
        "\n",
        "if result2['success']:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 2 RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    res = result2['result']\n",
        "    print(f\"\\n‚úÖ Assignment: {res['resource_name']} ({res['assigned_to']})\")\n",
        "    print(f\"\\nüìä Score: {res['score']['total_score']}/100\")\n",
        "    print(f\"\\nüí° AI Explanation:\")\n",
        "    print(f\"   {res['explanation']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ STARTING LANGGRAPH WORKFLOW\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "[AGENT 1: AddWorkAgent] Processing new work request\n",
            "============================================================\n",
            " Work Type: Mammography\n",
            " Description: Annual mammography screening for early detection\n",
            " Priority: 3/5\n",
            " Request Date: 2024-11-10\n",
            " ‚úÖ Work request created: W025\n",
            "\n",
            "============================================================\n",
            "[AGENT 2: WorkAnalyzerAgent] Analyzing W025\n",
            "============================================================\n",
            " Work Type: Mammography\n",
            " Priority: 3/5\n",
            " Required Specialty: Breast_Imaging_Specialist\n",
            " Alternate Specialty: General_Radiologist\n",
            " ‚úÖ Analysis complete\n",
            "\n",
            "============================================================\n",
            "[AGENT 3: ResourceFinderAgent] Finding matching resources\n",
            "============================================================\n",
            " Primary (Breast_Imaging_Specialist): 2 found\n",
            " ‚Ä¢ Dr. Patricia Taylor (Skill: 3/5)\n",
            " ‚Ä¢ Dr. William Moore (Skill: 5/5)\n",
            " Alternate (General_Radiologist): 4 found\n",
            " ‚Ä¢ Dr. John Smith (Skill: 4/5)\n",
            " ‚Ä¢ Dr. Emily Brown (Skill: 3/5)\n",
            " ‚Ä¢ Dr. Michael Davis (Skill: 3/5)\n",
            " ‚Ä¢ Dr. Alex Johnson (Skill: 4/5)\n",
            " ‚úÖ Total: 6 candidates\n",
            "\n",
            "============================================================\n",
            "[AGENT 4: AvailabilityCheckerAgent] Scoring candidates\n",
            "============================================================\n",
            " Request Date: 2024-11-10\n",
            "\n",
            " Scoring primary candidates...\n",
            " ‚Ä¢ Dr. Patricia Taylor: 64.7/100\n",
            " ‚Ä¢ Dr. William Moore: 85.7/100\n",
            "\n",
            " Scoring alternate candidates...\n",
            " ‚Ä¢ Dr. John Smith: 57.96/100 (alternate)\n",
            " ‚Ä¢ Dr. Emily Brown: 45.4/100 (alternate)\n",
            " ‚Ä¢ Dr. Michael Davis: 43.48/100 (alternate)\n",
            " ‚Ä¢ Dr. Alex Johnson: 45.68/100 (alternate)\n",
            "\n",
            " üìä Best match: Dr. William Moore\n",
            " üìä Score: 85.7/100\n",
            " ‚úÖ Selection complete\n",
            "\n",
            "============================================================\n",
            "[AGENT 5: AssignmentAgent] Finalizing assignment\n",
            "============================================================\n",
            " Updating database...\n",
            " ‚úÖ Updates completed:\n",
            "    - Status: pending ‚Üí assigned\n",
            "    - Assigned to: R015\n",
            "    - Total cases: +1\n",
            "    - Workload: +1\n",
            " Generating AI explanation...\n",
            " ‚úÖ Explanation generated\n",
            "\n",
            " ============================================================\n",
            " üéØ ASSIGNMENT COMPLETE\n",
            " ============================================================\n",
            " Work ID: W025\n",
            " Assigned To: Dr. William Moore\n",
            " Score: 85.7/100\n",
            "\n",
            "================================================================================\n",
            "‚úÖ LANGGRAPH WORKFLOW COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "SCENARIO 3 RESULTS\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Assignment: Dr. William Moore (R015)\n",
            "\n",
            "üìä Score: 85.7/100\n",
            "\n",
            "üí° AI Explanation:\n",
            "   Dr. William Moore was assigned based on Breast_Imaging_Specialist specialty, skill level 5/5, and 374 cases experience with current workload of 6 cases.\n",
            "\n",
            "üèÜ All Candidates (Exact vs Alternate):\n",
            "   1. Dr. William Moore: 85.7/100 [exact]\n",
            "   2. Dr. Patricia Taylor: 64.7/100 [exact]\n",
            "   3. Dr. John Smith: 57.96/100 [alternate]\n",
            "   4. Dr. Alex Johnson: 45.68/100 [alternate]\n",
            "   5. Dr. Emily Brown: 45.4/100 [alternate]\n",
            "   6. Dr. Michael Davis: 43.48/100 [alternate]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Scenario 3: Specialized Mammography (Priority 3)\n",
        "Demonstrates: Alternate specialty handling, 0.8x multiplier\n",
        "\"\"\"\n",
        "\n",
        "result3 = run_workflow(\n",
        "    db=db,\n",
        "    gemini_api_key=GEMINI_API_KEY,\n",
        "    work_type=\"Mammography\",\n",
        "    description=\"Annual mammography screening for early detection\",\n",
        "    priority=3\n",
        ")\n",
        "\n",
        "if result3['success']:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SCENARIO 3 RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    res = result3['result']\n",
        "    print(f\"\\n‚úÖ Assignment: {res['resource_name']} ({res['assigned_to']})\")\n",
        "    print(f\"\\nüìä Score: {res['score']['total_score']}/100\")\n",
        "    print(f\"\\nüí° AI Explanation:\")\n",
        "    print(f\"   {res['explanation']}\")\n",
        "    \n",
        "    print(f\"\\nüèÜ All Candidates (Exact vs Alternate):\")\n",
        "    for i, candidate in enumerate(result3['all_candidates'], 1):\n",
        "        match_type = candidate['score']['breakdown']['role_match_type']\n",
        "        print(f\"   {i}. {candidate['resource']['name']}: {candidate['score']['total_score']}/100 [{match_type}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üóÑÔ∏è  RADIOLOGY DATABASE INSPECTION\n",
            "================================================================================\n",
            "\n",
            "üìã WORK REQUESTS:\n",
            "work_id          work_type  priority    status assigned_to           timestamp\n",
            "   W001      CT_Scan_Chest         4   pending        None 2024-11-12 07:17:00\n",
            "   W002          MRI_Brain         4 completed        R011 2024-11-12 03:47:00\n",
            "   W003      CT_Scan_Chest         1   pending        None 2024-11-10 13:13:00\n",
            "   W004      CT_Scan_Brain         3   pending        None 2024-11-12 04:34:00\n",
            "   W005        Mammography         3  assigned        R015 2024-11-10 08:48:00\n",
            "   W006 Ultrasound_Abdomen         2   pending        None 2024-11-10 21:48:00\n",
            "   W007      CT_Scan_Chest         1   pending        None 2024-11-11 06:38:00\n",
            "   W008      CT_Scan_Brain         2   pending        None 2024-11-11 08:05:00\n",
            "   W009         X_Ray_Bone         3   pending        None 2024-11-10 10:42:00\n",
            "   W010        X_Ray_Chest         3   pending        None 2024-11-10 14:24:00\n",
            "   W011         X_Ray_Bone         2   pending        None 2024-11-10 21:42:00\n",
            "   W012      CT_Scan_Chest         2   pending        None 2024-11-10 23:10:00\n",
            "   W013        X_Ray_Chest         3  assigned        R009 2024-11-10 11:14:00\n",
            "   W014         X_Ray_Bone         2 completed        R013 2024-11-10 21:58:00\n",
            "   W015         X_Ray_Bone         3 completed        R005 2024-11-11 09:56:00\n",
            "   W016        Mammography         2   pending        None 2024-11-10 23:47:00\n",
            "   W017        X_Ray_Chest         3   pending        None 2024-11-11 09:23:00\n",
            "   W018          MRI_Brain         1   pending        None 2024-11-10 11:55:00\n",
            "   W019          MRI_Brain         2   pending        None 2024-11-11 08:24:00\n",
            "   W020        Mammography         3  assigned        R013 2024-11-10 08:43:00\n",
            "   W021          MRI_Brain         5   pending        None 2024-11-12 14:30:00\n",
            "   W022        MRI_Cardiac         5   pending        None 2024-11-12 15:45:00\n",
            "   W023          MRI_Brain         5  assigned        R005 2024-11-10 17:28:35\n",
            "   W024        X_Ray_Chest         2  assigned        R001 2024-11-11 17:28:37\n",
            "   W025        Mammography         3  assigned        R015 2024-11-10 17:28:38\n",
            "\n",
            "\n",
            "üë®‚Äç‚öïÔ∏è RESOURCES (Updated Case Counts):\n",
            "resource_id                  name                  specialty  skill_level  total_cases_handled\n",
            "       R012         Dr. David Lee Musculoskeletal_Specialist            5                  385\n",
            "       R015     Dr. William Moore  Breast_Imaging_Specialist            5                  375\n",
            "       R005        Dr. Sarah Chen                Neurologist            5                  346\n",
            "       R008        Dr. Kevin Park                Neurologist            4                  279\n",
            "       R007      Dr. Maria Garcia                Neurologist            4                  226\n",
            "       R004      Dr. Alex Johnson        General_Radiologist            4                  217\n",
            "       R009    Dr. Robert Johnson               Cardiologist            4                  189\n",
            "       R001        Dr. John Smith        General_Radiologist            4                  179\n",
            "       R011      Dr. Thomas White               Cardiologist            3                  179\n",
            "       R003     Dr. Michael Davis        General_Radiologist            3                  172\n",
            "       R002       Dr. Emily Brown        General_Radiologist            3                  100\n",
            "       R010     Dr. Lisa Anderson               Cardiologist            3                  100\n",
            "       R014   Dr. Patricia Taylor  Breast_Imaging_Specialist            3                   94\n",
            "       R013 Dr. Jennifer Martinez Musculoskeletal_Specialist            1                   61\n",
            "       R006      Dr. James Wilson                Neurologist            2                   33\n",
            "\n",
            "\n",
            "‚úÖ ASSIGNMENTS:\n",
            "work_id   work_type           assigned_to  total_cases_handled\n",
            "   W005 Mammography     Dr. William Moore                  375\n",
            "   W013 X_Ray_Chest    Dr. Robert Johnson                  189\n",
            "   W020 Mammography Dr. Jennifer Martinez                   61\n",
            "   W023   MRI_Brain        Dr. Sarah Chen                  346\n",
            "   W024 X_Ray_Chest        Dr. John Smith                  179\n",
            "   W025 Mammography     Dr. William Moore                  375\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "def inspect_database_complete(db_path=\"radiology.db\"):\n",
        "    \"\"\"Complete database inspection showing all tables and updates\"\"\"\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üóÑÔ∏è  RADIOLOGY DATABASE INSPECTION\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Show work requests\n",
        "    work_df = pd.read_sql_query(\"\"\"\n",
        "        SELECT work_id, work_type, priority, status, assigned_to, timestamp\n",
        "        FROM work_requests\n",
        "        ORDER BY work_id\n",
        "    \"\"\", conn)\n",
        "    print(\"\\nüìã WORK REQUESTS:\")\n",
        "    print(work_df.to_string(index=False))\n",
        "    \n",
        "    # Show updated case counts\n",
        "    resources_df = pd.read_sql_query(\"\"\"\n",
        "        SELECT resource_id, name, specialty, skill_level, total_cases_handled\n",
        "        FROM resources\n",
        "        ORDER BY total_cases_handled DESC\n",
        "    \"\"\", conn)\n",
        "    print(\"\\n\\nüë®‚Äç‚öïÔ∏è RESOURCES (Updated Case Counts):\")\n",
        "    print(resources_df.to_string(index=False))\n",
        "    \n",
        "    # Show assignment details\n",
        "    assignments_df = pd.read_sql_query(\"\"\"\n",
        "        SELECT w.work_id, w.work_type, r.name as assigned_to, r.total_cases_handled\n",
        "        FROM work_requests w\n",
        "        JOIN resources r ON w.assigned_to = r.resource_id\n",
        "        WHERE w.status = 'assigned'\n",
        "    \"\"\", conn)\n",
        "    print(\"\\n\\n‚úÖ ASSIGNMENTS:\")\n",
        "    print(assignments_df.to_string(index=False))\n",
        "    \n",
        "    conn.close()\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "inspect_database_complete()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Database connection closed\n",
            "\n",
            "üéâ Fixed implementation complete with true LangGraph orchestration!\n"
          ]
        }
      ],
      "source": [
        "# Clean up\n",
        "db.close()\n",
        "print(\"‚úÖ Database connection closed\")\n",
        "print(\"\\nüéâ Fixed implementation complete with true LangGraph orchestration!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
