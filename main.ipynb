{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Agent Work Allocation System using Strands\n",
        "\n",
        "**Architecture Overview**\n",
        "\n",
        "1. **Agent 1 - AddWorkAgent**: Accepts work request → inserts into database → returns work_id\n",
        "2. **Agent 2 - WorkAnalyzerAgent**: Analyzes work_id → determines required specialty/role\n",
        "3. **Agent 3 - ResourceFinderAgent**: Finds resources matching required specialty\n",
        "4. **Agent 4 - AvailabilityCheckerAgent**: Scores candidates based on multiple factors\n",
        "5. **Agent 5 - AssignmentAgent**: Updates database + generates LLM explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 1: Imports and Environment Setup\n",
        "import os\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "from datetime import datetime, time\n",
        "from typing import Dict, Optional, List\n",
        "from contextlib import contextmanager\n",
        "import json\n",
        "\n",
        "# Strands imports for multiagent system\n",
        "from strands import Agent, tool\n",
        "from strands.models import BedrockModel\n",
        "from strands.multiagent.graph import GraphBuilder\n",
        "from strands.models.gemini import GeminiModel\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Database Manager (Connection Pooling)\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"Singleton database connection manager with connection pooling\"\"\"\n",
        "    _engine = None\n",
        "\n",
        "    @classmethod\n",
        "    def get_engine(cls):\n",
        "        if cls._engine is None:\n",
        "            DB_USER = os.getenv('DB_USER', 'work_user')\n",
        "            DB_PW = os.getenv('DB_PASSWORD', 'work_password')\n",
        "            DB_NAME = os.getenv('DB_NAME', 'work_allocation')\n",
        "            DB_HOST = os.getenv('DB_HOST', 'localhost')\n",
        "            DB_PORT = os.getenv('DB_PORT', '3307')\n",
        "\n",
        "            cls._engine = create_engine(\n",
        "                f\"mysql+pymysql://{DB_USER}:{DB_PW}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
        "                pool_pre_ping=True,\n",
        "                pool_size=5,\n",
        "                max_overflow=10\n",
        "            )\n",
        "            print(\"Database engine created\")\n",
        "        return cls._engine\n",
        "    \n",
        "    @classmethod\n",
        "    @contextmanager\n",
        "    def transaction(cls):\n",
        "        engine = cls.get_engine()\n",
        "        conn = engine.connect()\n",
        "        trans = conn.begin()\n",
        "        try:\n",
        "            yield conn\n",
        "            trans.commit()\n",
        "        except Exception as e:\n",
        "            trans.rollback()\n",
        "            print(f\"Transaction rolled back: {e}\")\n",
        "            raise\n",
        "        finally:\n",
        "            conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Database Helper Functions\n",
        "\n",
        "def run_sql(query: str, params: Optional[Dict] = None):\n",
        "    \"\"\"Execute SQL query with proper error handling\"\"\"\n",
        "    try:\n",
        "        engine = DatabaseManager.get_engine()\n",
        "        with engine.begin() as conn:\n",
        "            result = conn.execute(text(query), params or {})\n",
        "            if result.returns_rows:\n",
        "                return pd.DataFrame(result.fetchall(), columns=result.keys())\n",
        "            return result.rowcount\n",
        "    except Exception as e:\n",
        "        print(f\"SQL execution error: {e}\")\n",
        "        raise\n",
        "\n",
        "def initialize_database(reset=True):\n",
        "    \"\"\"Initialize database schema and load CSV data\"\"\"\n",
        "    print(\"Initializing database from CSV files\")\n",
        "    engine = DatabaseManager.get_engine()\n",
        "\n",
        "    if reset:\n",
        "        with engine.begin() as conn:\n",
        "            conn.execute(text(\"SET FOREIGN_KEY_CHECKS=0;\"))\n",
        "            tables = ['assignment_log', 'work_requests', 'resource_calendar', 'specialty_mapping', 'resources']\n",
        "            for table in tables:\n",
        "                conn.execute(text(f\"DROP TABLE IF EXISTS {table};\"))\n",
        "            conn.execute(text(\"SET FOREIGN_KEY_CHECKS=1;\"))\n",
        "\n",
        "        # Create schema\n",
        "        with engine.begin() as conn:\n",
        "            # Resources table\n",
        "            conn.execute(text(\"\"\"\n",
        "                CREATE TABLE resources (\n",
        "                    resource_id VARCHAR(10) PRIMARY KEY,\n",
        "                    name VARCHAR(100) NOT NULL,\n",
        "                    specialty VARCHAR(50) NOT NULL,\n",
        "                    skill_level INT NOT NULL CHECK (skill_level BETWEEN 1 AND 5),\n",
        "                    total_cases_handled INT DEFAULT 0\n",
        "                )\n",
        "            \"\"\"))\n",
        "            \n",
        "            # Resource calendar table\n",
        "            conn.execute(text(\"\"\"\n",
        "                CREATE TABLE resource_calendar (\n",
        "                    calendar_id VARCHAR(10) PRIMARY KEY,\n",
        "                    resource_id VARCHAR(10) NOT NULL,\n",
        "                    date DATE NOT NULL,\n",
        "                    available_from TIME NOT NULL,\n",
        "                    available_to TIME NOT NULL,\n",
        "                    current_workload INT DEFAULT 0,\n",
        "                    FOREIGN KEY (resource_id) REFERENCES resources(resource_id)\n",
        "                )\n",
        "            \"\"\"))\n",
        "            \n",
        "            # Work requests table\n",
        "            conn.execute(text(\"\"\"\n",
        "                CREATE TABLE work_requests (\n",
        "                    work_id VARCHAR(10) PRIMARY KEY,\n",
        "                    work_type VARCHAR(50) NOT NULL,\n",
        "                    description TEXT,\n",
        "                    priority INT NOT NULL CHECK (priority BETWEEN 1 AND 5),\n",
        "                    timestamp DATETIME NOT NULL,\n",
        "                    status VARCHAR(20) DEFAULT 'pending',\n",
        "                    assigned_to VARCHAR(10),\n",
        "                    FOREIGN KEY (assigned_to) REFERENCES resources(resource_id)\n",
        "                )\n",
        "            \"\"\"))\n",
        "            \n",
        "            # Specialty mapping table\n",
        "            conn.execute(text(\"\"\"\n",
        "                CREATE TABLE specialty_mapping (\n",
        "                    work_type VARCHAR(50) PRIMARY KEY,\n",
        "                    required_specialty VARCHAR(50) NOT NULL,\n",
        "                    alternate_specialty VARCHAR(50)\n",
        "                )\n",
        "            \"\"\"))\n",
        "            \n",
        "            # Assignment log table\n",
        "            conn.execute(text(\"\"\"\n",
        "                CREATE TABLE assignment_log (\n",
        "                    log_id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "                    work_id VARCHAR(10) NOT NULL,\n",
        "                    resource_id VARCHAR(10) NOT NULL,\n",
        "                    assignment_timestamp DATETIME NOT NULL,\n",
        "                    match_score FLOAT,\n",
        "                    reasoning TEXT,\n",
        "                    FOREIGN KEY (work_id) REFERENCES work_requests(work_id),\n",
        "                    FOREIGN KEY (resource_id) REFERENCES resources(resource_id)\n",
        "                )\n",
        "            \"\"\"))\n",
        "\n",
        "        # Load CSV data\n",
        "\n",
        "        # Resources\n",
        "        resources_df = pd.read_csv('data/resources.csv')\n",
        "        resources_df.to_sql('resources', engine, if_exists='append', index=False)\n",
        "        \n",
        "        # Resource Calendar\n",
        "        calendar_df = pd.read_csv('data/resource_calendar.csv')\n",
        "        calendar_df.to_sql('resource_calendar', engine, if_exists='append', index=False)\n",
        "        \n",
        "        # Specialty Mapping\n",
        "        mapping_df = pd.read_csv('data/specialty_mapping.csv')\n",
        "        mapping_df['alternate_specialty'] = mapping_df['alternate_specialty'].where(\n",
        "            pd.notna(mapping_df['alternate_specialty']), None\n",
        "        )\n",
        "        mapping_df.to_sql('specialty_mapping', engine, if_exists='append', index=False)\n",
        "\n",
        "        # Work Requests\n",
        "        work_requests_df = pd.read_csv('data/work_requests.csv')\n",
        "        work_requests_df['timestamp'] = pd.to_datetime(work_requests_df['timestamp'])\n",
        "        work_requests_df.to_sql('work_requests', engine, if_exists='append', index=False)\n",
        "                \n",
        "        print(\"Database initialization complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Tool Functions for Agents\n",
        "\n",
        "# Agent 1 Tools\n",
        "@tool\n",
        "def add_work_tool(work_type: str, description: str, priority: int, timestamp: str) -> Dict:\n",
        "    \"\"\"Add work request to database - O(1) operation\"\"\"\n",
        "    try:\n",
        "        # Generate new work_id\n",
        "        count_result = run_sql(\"SELECT COUNT(*) as cnt FROM work_requests\")\n",
        "        work_id = f\"W{int(count_result['cnt'].iloc[0]) + 1:03d}\"  # W001 format (3 digits)\n",
        "        \n",
        "        # Insert work request\n",
        "        run_sql(\n",
        "            \"\"\"INSERT INTO work_requests (work_id, work_type, description, priority, timestamp, status)\n",
        "               VALUES (:work_id, :work_type, :description, :priority, :timestamp, 'pending')\"\"\",\n",
        "            {\n",
        "                'work_id': work_id,\n",
        "                'work_type': work_type,\n",
        "                'description': description,\n",
        "                'priority': priority,\n",
        "                'timestamp': timestamp\n",
        "            }\n",
        "        )\n",
        "        return {'work_id': work_id, 'status': 'success'}\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Agent 2 Tools\n",
        "@tool\n",
        "def analyze_work_tool(work_id: str) -> Dict:\n",
        "    \"\"\"Analyze work request and determine required specialty - O(1) operation\"\"\"\n",
        "    try:\n",
        "        # Get work details\n",
        "        work_df = run_sql(\n",
        "            \"SELECT work_type, priority FROM work_requests WHERE work_id = :work_id\",\n",
        "            {'work_id': work_id}\n",
        "        )\n",
        "        if work_df.empty:\n",
        "            return {'error': 'Work request not found'}\n",
        "        \n",
        "        work_type = work_df.iloc[0]['work_type']\n",
        "        priority = int(work_df.iloc[0]['priority'])\n",
        "        \n",
        "        # Get required specialty\n",
        "        specialty_df = run_sql(\n",
        "            \"SELECT required_specialty, alternate_specialty FROM specialty_mapping WHERE work_type = :work_type\",\n",
        "            {'work_type': work_type}\n",
        "        )\n",
        "        if specialty_df.empty:\n",
        "            return {'error': 'No specialty mapping found'}\n",
        "        \n",
        "        return {\n",
        "            'required_specialty': specialty_df.iloc[0]['required_specialty'],\n",
        "            'alternate_specialty': specialty_df.iloc[0]['alternate_specialty'],\n",
        "            'priority': priority,\n",
        "            'work_type': work_type,\n",
        "            'work_id': work_id\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Agent 3 Tools\n",
        "@tool\n",
        "def find_resources_tool(work_id: str, required_specialty: str, alternate_specialty: str, timestamp: str) -> Dict:\n",
        "    \"\"\"Find resources matching required specialty - O(n) where n is matching resources\"\"\"\n",
        "    try:\n",
        "        # Parse date from timestamp\n",
        "        work_date = datetime.strptime(timestamp.split()[0], '%Y-%m-%d').date()\n",
        "        \n",
        "        # Find resources with matching specialty\n",
        "        query = \"\"\"\n",
        "        SELECT r.resource_id, r.name, r.specialty, r.skill_level, r.total_cases_handled,\n",
        "               rc.available_from, rc.available_to, rc.current_workload\n",
        "        FROM resources r\n",
        "        INNER JOIN resource_calendar rc ON r.resource_id = rc.resource_id\n",
        "        WHERE (r.specialty = :required_specialty OR r.specialty = :alternate_specialty)\n",
        "        AND rc.date = :work_date\n",
        "        \"\"\"\n",
        "        \n",
        "        resources_df = run_sql(query, {\n",
        "            'required_specialty': required_specialty,\n",
        "            'alternate_specialty': alternate_specialty if alternate_specialty else required_specialty,\n",
        "            'work_date': work_date\n",
        "        })\n",
        "        \n",
        "        if resources_df.empty:\n",
        "            return {'candidates': [], 'count': 0}\n",
        "        \n",
        "        candidates = resources_df.to_dict('records')\n",
        "        \n",
        "        return {\n",
        "            'work_id': work_id,\n",
        "            'candidates': candidates,\n",
        "            'count': len(candidates),\n",
        "            'timestamp': timestamp\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Agent 4 Tools\n",
        "@tool\n",
        "def score_candidates_tool(work_id: str, candidates: List[Dict], priority: int, required_specialty: str, timestamp: str) -> Dict:\n",
        "    \"\"\"Score candidates based on multiple criteria - O(n log n) for sorting\"\"\"\n",
        "    try:\n",
        "        if not candidates:\n",
        "            return {'error': 'No candidates to score'}\n",
        "        \n",
        "        work_time = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S').time()\n",
        "        scored_candidates = []\n",
        "        \n",
        "        for candidate in candidates:\n",
        "            # BASE SCORING (Total = 100 points)\n",
        "            \n",
        "            # 1. Role match (40 points)\n",
        "            role_score = 40 if candidate['specialty'] == required_specialty else 20\n",
        "            \n",
        "            # 2. Skill level (20 points)\n",
        "            skill_score = candidate['skill_level'] * 4\n",
        "            \n",
        "            # 3. Experience (15 points)\n",
        "            experience_score = min(candidate['total_cases_handled'] / 10, 15)\n",
        "            \n",
        "            # 4. Availability (15 points)\n",
        "            available_from = candidate['available_from']\n",
        "            available_to = candidate['available_to']\n",
        "            \n",
        "            # Handle timedelta format\n",
        "            if hasattr(available_from, 'total_seconds'):\n",
        "                seconds = int(available_from.total_seconds())\n",
        "                available_from = time(seconds // 3600, (seconds % 3600) // 60, seconds % 60)\n",
        "            elif isinstance(available_from, str):\n",
        "                if 'days' in available_from:\n",
        "                    time_part = available_from.split()[-1]\n",
        "                    available_from = datetime.strptime(time_part, '%H:%M:%S').time()\n",
        "                else:\n",
        "                    available_from = datetime.strptime(available_from, '%H:%M:%S').time()\n",
        "            \n",
        "            if hasattr(available_to, 'total_seconds'):\n",
        "                seconds = int(available_to.total_seconds())\n",
        "                available_to = time(seconds // 3600, (seconds % 3600) // 60, seconds % 60)\n",
        "            elif isinstance(available_to, str):\n",
        "                if 'days' in available_to:\n",
        "                    time_part = available_to.split()[-1]\n",
        "                    available_to = datetime.strptime(time_part, '%H:%M:%S').time()\n",
        "                else:\n",
        "                    available_to = datetime.strptime(available_to, '%H:%M:%S').time()\n",
        "            \n",
        "            is_available = available_from <= work_time <= available_to\n",
        "            availability_score = 15 if is_available else 5\n",
        "            \n",
        "            # 5. Workload (10 points)\n",
        "            workload = candidate['current_workload']\n",
        "            workload_score = max(10 - workload * 2, 0)\n",
        "            \n",
        "            # PRIORITY HANDLING\n",
        "            priority_bonus_applied = False\n",
        "            if priority >= 4 and workload < 3 and is_available:\n",
        "                availability_score = min(availability_score + 5, 20)\n",
        "                workload_score = min(workload_score + 5, 15)\n",
        "                priority_bonus_applied = True\n",
        "            \n",
        "            total_score = role_score + skill_score + experience_score + availability_score + workload_score\n",
        "            \n",
        "            scored_candidates.append({\n",
        "                'resource_id': candidate['resource_id'],\n",
        "                'name': candidate['name'],\n",
        "                'specialty': candidate['specialty'],\n",
        "                'skill_level': candidate['skill_level'],\n",
        "                'total_cases_handled': candidate['total_cases_handled'],\n",
        "                'current_workload': candidate['current_workload'],\n",
        "                'total_score': round(min(total_score, 100), 2),\n",
        "                'role_score': role_score,\n",
        "                'skill_score': skill_score,\n",
        "                'experience_score': round(experience_score, 2),\n",
        "                'availability_score': availability_score,\n",
        "                'workload_score': workload_score,\n",
        "                'priority_bonus': '+5 urgent' if priority_bonus_applied else 'none'\n",
        "            })\n",
        "        \n",
        "        # Sort by total score (descending)\n",
        "        scored_candidates.sort(key=lambda x: x['total_score'], reverse=True)\n",
        "        \n",
        "        # Return best match + 2 runners-up + scoring explanation\n",
        "        best = scored_candidates[0]\n",
        "        runners_up = scored_candidates[1:3] if len(scored_candidates) > 1 else []\n",
        "        \n",
        "        return {\n",
        "            'work_id': work_id,\n",
        "            'match_score': best['total_score'],\n",
        "            'resource_id': best['resource_id'],\n",
        "            'best_match': best,\n",
        "            'runners_up': runners_up,  # For XAI comparison\n",
        "            'scoring_logic': {\n",
        "                'total': 100,\n",
        "                'breakdown': {\n",
        "                    'role_match': f\"{best['role_score']}/40\",\n",
        "                    'skill': f\"{best['skill_score']}/20\",\n",
        "                    'experience': f\"{best['experience_score']}/15\",\n",
        "                    'availability': f\"{best['availability_score']}/15\",\n",
        "                    'workload': f\"{best['workload_score']}/10\"\n",
        "                },\n",
        "                'priority_bonus': best['priority_bonus']\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "\n",
        "# Agent 5 Tools\n",
        "@tool\n",
        "def assign_work_tool(work_id: str, resource_id: str, match_score: float) -> Dict:\n",
        "    \"\"\"Update database with assignment + validation - O(1) operation\"\"\"\n",
        "    try:\n",
        "        # Validate IDs format (W### and R### format)\n",
        "        if not work_id.startswith('W') or len(work_id) != 4:\n",
        "            return {'error': f'Invalid work_id format: {work_id}. Must be W### (e.g., W001, W023)'}\n",
        "        \n",
        "        if not resource_id.startswith('R') or len(resource_id) != 4:\n",
        "            return {'error': f'Invalid resource_id format: {resource_id}. Must be R### (e.g., R001, R005)'}\n",
        "        \n",
        "        # Check if work_id exists\n",
        "        work_check = run_sql(\n",
        "            \"SELECT work_id FROM work_requests WHERE work_id = :work_id\",\n",
        "            {'work_id': work_id}\n",
        "        )\n",
        "        if work_check.empty:\n",
        "            return {'error': f'Work ID {work_id} not found in database'}\n",
        "        \n",
        "        # Check if resource_id exists\n",
        "        resource_check = run_sql(\n",
        "            \"SELECT resource_id FROM resources WHERE resource_id = :resource_id\",\n",
        "            {'resource_id': resource_id}\n",
        "        )\n",
        "        if resource_check.empty:\n",
        "            return {'error': f'Resource ID {resource_id} not found in database'}\n",
        "        \n",
        "        # Assign work in work_requests table\n",
        "        run_sql(\n",
        "            \"UPDATE work_requests SET assigned_to = :resource_id, status = 'assigned' WHERE work_id = :work_id\",\n",
        "            {'resource_id': resource_id, 'work_id': work_id}\n",
        "        )\n",
        "        \n",
        "        # Update resource_calendar workload for assigned date and resource\n",
        "        run_sql(\n",
        "            \"UPDATE resource_calendar SET current_workload = current_workload + 1 WHERE resource_id = :resource_id AND date = (SELECT DATE(timestamp) FROM work_requests WHERE work_id = :work_id)\",\n",
        "            {'resource_id': resource_id, 'work_id': work_id}\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'status': 'success', \n",
        "            'work_id': work_id, \n",
        "            'resource_id': resource_id,\n",
        "            'message': f'Successfully assigned {work_id} to {resource_id}',\n",
        "            'match_score': match_score\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {'status': 'failure', 'error': str(e)}\n",
        "\n",
        "\n",
        "@tool\n",
        "def log_assignment_tool(work_id: str, resource_id: str, match_score: float, reasoning: str) -> Dict:\n",
        "    \"\"\"Log assignment to database - O(1) operation\"\"\"\n",
        "    try:\n",
        "        run_sql(\n",
        "            \"\"\"INSERT INTO assignment_log (work_id, resource_id, assignment_timestamp, match_score, reasoning)\n",
        "               VALUES (:work_id, :resource_id, NOW(), :match_score, :reasoning)\"\"\",\n",
        "            {\n",
        "                'work_id': work_id,\n",
        "                'resource_id': resource_id,\n",
        "                'match_score': match_score,\n",
        "                'reasoning': reasoning\n",
        "            }\n",
        "        )\n",
        "        return {'status': 'logged'}\n",
        "    except Exception as e:\n",
        "        return {'status': 'failure', 'error': str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: LLM Setup with Bedrock Primary + Gemini Fallback\n",
        "\n",
        "# LLM providers implemented by Strands Agents SDK\n",
        "def get_bedrock_model():\n",
        "    \"\"\"Get Bedrock model with proper configuration\"\"\"\n",
        "    try:\n",
        "        return BedrockModel(\n",
        "            model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
        "            region_name=\"us-east-1\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Bedrock model initialization failed: {e}\")\n",
        "        return None\n",
        "    \n",
        "def get_gemini_model():\n",
        "    \"\"\"Get Gemini model with proper configuration\"\"\"\n",
        "    try:\n",
        "        return GeminiModel(\n",
        "                    client_args={\n",
        "                        \"api_key\": os.getenv('GOOGLE_API_KEY'),\n",
        "                    },\n",
        "                    model_id=\"gemini-2.5-flash\"\n",
        "                )\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini model initialization failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Reasoning Generation Function\n",
        "def generate_assignment_reasoning_llm(work_data: Dict, resource_data: Dict) -> str:\n",
        "    \"\"\"\n",
        "    Generate human-readable explanation using LLM with few-shot prompting.\n",
        "    Primary: AWS Bedrock (Claude)\n",
        "    Fallback: Google Gemini\n",
        "    \"\"\"\n",
        "    # Few-shot examples for better output quality\n",
        "    few_shot_examples = \"\"\"\n",
        "Example 1:\n",
        "Input: MRI_Brain, Priority 5, Dr. Sarah Chen, Neurology, Skill 5, 150 cases, 2 current workload\n",
        "Output: Dr. Sarah Chen was assigned to this urgent MRI_Brain case due to her specialized neurology expertise (150+ cases) and immediate availability with only 2 current cases, making her optimal for this Priority 5 request.\n",
        "\n",
        "Example 2:\n",
        "Input: CT_Chest, Priority 3, Dr. John Smith, Radiology, Skill 4, 80 cases, 4 current workload\n",
        "Output: Dr. John Smith was selected for this CT_Chest scan based on his solid radiology background (80 cases) and skill level 4 proficiency, despite a moderate workload of 4 cases.\n",
        "\n",
        "Example 3:\n",
        "Input: Ultrasound_Abdomen, Priority 2, Dr. Emily Davis, General Imaging, Skill 3, 45 cases, 1 current workload\n",
        "Output: Dr. Emily Davis was assigned to this routine Ultrasound_Abdomen procedure given her general imaging qualification, manageable experience (45 cases), and light current workload of only 1 case.\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"\"\"{few_shot_examples}\n",
        "\n",
        "Now generate a similar professional explanation for this assignment:\n",
        "Work Type: {work_data['work_type']}\n",
        "Priority: {work_data['priority']}\n",
        "Resource Name: {resource_data['name']}\n",
        "Specialty: {resource_data['specialty']}\n",
        "Skill Level: {resource_data['skill_level']}\n",
        "Cases Handled: {resource_data['total_cases_handled']}\n",
        "Current Workload: {resource_data['current_workload']}\n",
        "Match Score: {resource_data['total_score']}/100\n",
        "\n",
        "Generate a 2-3 sentence professional explanation:\"\"\"\n",
        "    \n",
        "    # Try Bedrock first\n",
        "    try:\n",
        "        bedrock_model = get_bedrock_model()\n",
        "        if bedrock_model:\n",
        "            agent = Agent(\n",
        "                name=\"ReasoningGenerator\",\n",
        "                model=bedrock_model,\n",
        "                instructions=\"You are an expert at explaining resource allocation decisions clearly and professionally.\"\n",
        "            )\n",
        "            result = agent(prompt)\n",
        "            reasoning = result.output.text.strip()\n",
        "            if reasoning:\n",
        "                print(\"Used Bedrock for reasoning generation\")\n",
        "                return reasoning\n",
        "    except Exception as e:\n",
        "        print(f\"Bedrock failed: {e}, falling back to Gemini\")\n",
        "    \n",
        "    # Fallback to Gemini\n",
        "    try:\n",
        "        gemini_model = get_gemini_model()\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        reasoning = response.text.strip()\n",
        "        print(\"Used Gemini fallback for reasoning generation\")\n",
        "        return reasoning\n",
        "    except Exception as e:\n",
        "        print(f\"Both LLMs failed: {e}\")\n",
        "        # Fallback to template-based reasoning\n",
        "        return f\"{resource_data['name']} was assigned to this {work_data['work_type']} case (Priority {work_data['priority']}) based on {resource_data['specialty']} expertise, skill level {resource_data['skill_level']}, and {resource_data['total_cases_handled']} cases handled with current workload of {resource_data['current_workload']} cases (Match Score: {resource_data['total_score']}/100).\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: 5 Strands Agents\n",
        "\n",
        "# Agent 1: AddWorkAgent - Accepts work request and adds to database\n",
        "add_work_agent = Agent(\n",
        "    name=\"AddWorkAgent\",\n",
        "    model=get_gemini_model(),  # Need model for orchestration, but won't use for LLM reasoning\n",
        "    system_prompt=\"\"\"You are a work intake specialist. When given work request details:\n",
        "    1. Use the add_work_tool to insert the work into the database\n",
        "    2. Return the work_id that was generated\n",
        "    3. Respond with JSON format: {\"work_id\": \"WR####\", \"status\": \"success\"}\"\"\",\n",
        "    tools=[add_work_tool]\n",
        ")\n",
        "\n",
        "# Agent 2: WorkAnalyzerAgent - Analyzes work request to determine required specialty\n",
        "work_analyzer_agent = Agent(\n",
        "    name=\"WorkAnalyzerAgent\",\n",
        "    model=get_gemini_model(),\n",
        "    system_prompt=\"Call analyze_work_tool with the work_id from the scenario input. Return the exact output without modification.\",\n",
        "    tools=[analyze_work_tool]\n",
        ")\n",
        "\n",
        "# Agent 3: ResourceFinderAgent - Finds resources based on required specialty\n",
        "resource_finder_agent = Agent(\n",
        "    name=\"ResourceFinderAgent\",\n",
        "    model=get_gemini_model(),\n",
        "    system_prompt=\"Call find_resources_tool with work_id, required_specialty, alternate_specialty, timestamp. Return the exact output.\",\n",
        "    tools=[find_resources_tool]\n",
        ")\n",
        "\n",
        "# Agent 4: AvailabilityCheckerAgent - Scores candidates based on multiple criteria\n",
        "availability_checker_agent = Agent(\n",
        "    name=\"AvailabilityCheckerAgent\",\n",
        "    model=get_gemini_model(),\n",
        "    system_prompt=\"Call score_candidates_tool with the work_id, candidates list, priority, required_specialty, and timestamp. Return the exact output without adding explanations or making any modifications.\",\n",
        "    tools=[score_candidates_tool]\n",
        ")\n",
        "\n",
        "# Agent 5: AssignmentAgent - Assigns work to best matched resource and logs the assignment with reasoning (+ updates DB)\n",
        "assignment_agent = Agent(\n",
        "    name=\"AssignmentAgent\",\n",
        "    model=get_gemini_model(),\n",
        "    system_prompt=\"\"\"\n",
        "You assign work to resources.\n",
        "\n",
        "STEP 1: Use the work_id, resource_id, match_score passed through the scenario input.\n",
        "CRITICAL: Before proceeding, validate that work_id is in format W###, resource_id is in format R###, match_score is a number between 0 and 100. Donot proceed if formats are incorrect. If invalid, return an error message indicating the issue.\n",
        "\n",
        "STEP 3: Assign and log:\n",
        "1. assign_work_tool(work_id, resource_id, match_score)\n",
        "2. Generate a 2-sentence reasoning using best_match data and scoring_logic.\n",
        "3. log_assignment_tool(work_id, resource_id, match_score, reasoning)\n",
        "\n",
        "Return the assignment status.\n",
        "\"\"\",\n",
        "    tools=[assign_work_tool, log_assignment_tool]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strands Graph built successfully\n",
            "Pipeline: Agent1 → Agent2 → Agent3 → Agent4 → Agent5\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Strands Graph Connecting the 5 Agents\n",
        "builder = GraphBuilder()\n",
        "\n",
        "agent1_node = builder.add_node(add_work_agent, node_id=\"agent1_add_work\")\n",
        "agent2_node = builder.add_node(work_analyzer_agent, node_id=\"agent2_analyze\")\n",
        "agent3_node = builder.add_node(resource_finder_agent, node_id=\"agent3_find_resources\")\n",
        "agent4_node = builder.add_node(availability_checker_agent, node_id=\"agent4_score\")\n",
        "agent5_node = builder.add_node(assignment_agent, node_id=\"agent5_assign\")\n",
        "\n",
        "builder.add_edge(\"agent1_add_work\", \"agent2_analyze\")\n",
        "builder.add_edge(\"agent2_analyze\", \"agent3_find_resources\")\n",
        "builder.add_edge(\"agent3_find_resources\", \"agent4_score\")\n",
        "builder.add_edge(\"agent4_score\", \"agent5_assign\")\n",
        "\n",
        "builder.set_entry_point(\"agent1_add_work\")\n",
        "\n",
        "builder.set_max_node_executions(10)  # Limited retries to 10\n",
        "builder.set_execution_timeout(600.0)  # 10 minutes total timeout\n",
        "builder.set_node_timeout(180.0)  # 3 minutes per node timeout\n",
        "\n",
        "work_allocation_graph = builder.build()\n",
        "print('Strands Graph built successfully')\n",
        "print('Pipeline: Agent1 → Agent2 → Agent3 → Agent4 → Agent5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing database from CSV files\n",
            "Database engine created\n",
            "Database initialization complete\n",
            "Database initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Initialize Database\n",
        "initialize_database(reset=False)\n",
        "print(\"Database initialized successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SCENARIO 1: Urgent MRI_Brain - Neurology Specialist Required\n",
            "================================================================================\n",
            "\n",
            "Tool #1: add_work_tool\n",
            "{\"work_id\": \"W023\", \"status\": \"success\"}\n",
            "Tool #1: analyze_work_tool\n",
            "{\"analyze_work_tool_response\": {\"output\": [{\"text\": \"{\\'required_specialty\\': \\'Neurologist\\', \\'alternate_specialty\\': \\'General_Radiologist\\', \\'priority\\': 5, \\'work_type\\': \\'MRI_Brain\\', \\'work_id\\': \\'W023\\'}\"}]}}\n",
            "Tool #1: find_resources_tool\n",
            "{\"find_resources_tool_response\": {\"output\": [{\"text\": \"{\\'work_id\\': \\'W023\\', \\'candidates\\': [{\\'resource_id\\': \\'R001\\', \\'name\\': \\'Dr. John Smith\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 178, \\'available_from\\': Timedelta(\\'0 days 07:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 19:00:00\\'), \\'current_workload\\': 5}, {\\'resource_id\\': \\'R002\\', \\'name\\': \\'Dr. Emily Brown\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 100, \\'available_from\\': Timedelta(\\'0 days 13:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 18:00:00\\'), \\'current_workload\\': 2}, {\\'resource_id\\': \\'R003\\', \\'name\\': \\'Dr. Michael Davis\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 172, \\'available_from\\': Timedelta(\\'0 days 13:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 18:00:00\\'), \\'current_workload\\': 6}, {\\'resource_id\\': \\'R004\\', \\'name\\': \\'Dr. Alex Johnson\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 217, \\'available_from\\': Timedelta(\\'0 days 08:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 13:00:00\\'), \\'current_workload\\': 9}, {\\'resource_id\\': \\'R005\\', \\'name\\': \\'Dr. Sarah Chen\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 5, \\'total_cases_handled\\': 345, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 3}, {\\'resource_id\\': \\'R006\\', \\'name\\': \\'Dr. James Wilson\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 2, \\'total_cases_handled\\': 33, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 0}, {\\'resource_id\\': \\'R007\\', \\'name\\': \\'Dr. Maria Garcia\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 226, \\'available_from\\': Timedelta(\\'0 days 08:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 13:00:00\\'), \\'current_workload\\': 6}, {\\'resource_id\\': \\'R008\\', \\'name\\': \\'Dr. Kevin Park\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 279, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 8}], \\'count\\': 8, \\'timestamp\\': \\'2024-11-10 09:30:00\\'}\"}]}\n",
            "Tool #1: score_candidates_tool\n",
            "\n",
            "Tool #2: score_candidates_tool\n",
            "{\"score_candidates_tool_response\": {\"output\": [{\"text\": \"{\\'work_id\\': \\'W023\\', \\'match_score\\': 94, \\'resource_id\\': \\'R005\\', \\'best_match\\': {\\'resource_id\\': \\'R005\\', \\'name\\': \\'Dr. Sarah Chen\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 5, \\'total_cases_handled\\': 345, \\'current_workload\\': 3, \\'total_score\\': 94, \\'role_score\\': 40, \\'skill_score\\': 20, \\'experience_score\\': 15, \\'availability_score\\': 15, \\'workload_score\\': 4, \\'priority_bonus\\': \\'none\\'}, \\'runners_up\\': [{\\'resource_id\\': \\'R006\\', \\'name\\': \\'Dr. James Wilson\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 2, \\'total_cases_handled\\': 33, \\'current_workload\\': 0, \\'total_score\\': 86.3, \\'role_score\\': 40, \\'skill_score\\': 8, \\'experience_score\\': 3.3, \\'availability_score\\': 20, \\'workload_score\\': 15, \\'priority_bonus\\': \\'+5 urgent\\'}, {\\'resource_id\\': \\'R007\\', \\'name\\': \\'Dr. Maria Garcia\\', \\'specialty\\': \\'Neurologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 226, \\'current_workload\\': 6, \\'total_score\\': 86, \\'role_score\\': 40, \\'skill_score\\': 16, \\'experience_score\\': 15, \\'availability_score\\': 15, \\'workload_score\\': 0, \\'priority_bonus\\': \\'none\\'}], \\'scoring_logic\\': {\\'total\\': 100, \\'breakdown\\': {\\'role_match\\': \\'40/40\\', \\'skill\\': \\'20/20\\', \\'experience\\': \\'15/15\\', \\'availability\\': \\'15/15\\', \\'workload\\': \\'4/10\\'}, \\'priority_bonus\\': \\'none\\'}}\"}]}\n",
            "Tool #1: assign_work_tool\n",
            "\n",
            "Tool #2: log_assignment_tool\n",
            "Assignment Status: {'status': 'success', 'work_id': 'W023', 'resource_id': 'R005', 'message': 'Successfully assigned W023 to R005', 'match_score': 94.0}\n",
            "\n",
            "--- Execution Result ---\n",
            "Status: Status.COMPLETED\n",
            "\n",
            "--- Assignment Log ---\n",
            " log_id work_id resource_id assignment_timestamp  match_score                                                                                                                                                                                                                                                                                                                                                   reasoning\n",
            "      1    W023        R005  2025-11-19 18:42:03         94.0 Dr. Sarah Chen (R005) is the best match for work W023 with a score of 94, demonstrating an exceptional fit based on her specialty as a Neurologist, high skill level, and extensive experience. Her high availability and perfect role match, alongside a reasonable current workload, further solidify this assignment, despite a moderate workload score.\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Scenario 1 - Urgent MRI_Brain Case (Priority 5)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCENARIO 1: Urgent MRI_Brain - Neurology Specialist Required\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scenario1_input = {\n",
        "    \"work_type\": \"MRI_Brain\",\n",
        "    \"description\": \"Urgent brain MRI for suspected stroke patient\",\n",
        "    \"priority\": 5,\n",
        "    \"timestamp\": \"2024-11-10 09:30:00\"\n",
        "}\n",
        "\n",
        "# Execute graph\n",
        "result1 = work_allocation_graph(json.dumps(scenario1_input))\n",
        "\n",
        "print(\"\\n--- Execution Result ---\")\n",
        "print(f\"Status: {result1.status}\")\n",
        "\n",
        "# Display assignment log\n",
        "log_df = run_sql(\"SELECT * FROM assignment_log ORDER BY log_id DESC LIMIT 1\")\n",
        "if not log_df.empty:\n",
        "    print(\"\\n--- Assignment Log ---\")\n",
        "    print(log_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n--- No assignments logged yet ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SCENARIO 2: Routine Ultrasound_Abdomen - General Imaging Specialist\n",
            "================================================================================\n",
            "\n",
            "Tool #2: add_work_tool\n",
            "{\"work_id\": \"W024\", \"status\": \"success\"}\n",
            "Tool #2: analyze_work_tool\n",
            "{\"analyze_work_tool_response\": {\"output\": [{\"text\": \"{\\'required_specialty\\': \\'General_Radiologist\\', \\'alternate_specialty\\': None, \\'priority\\': 2, \\'work_type\\': \\'Ultrasound_Abdomen\\', \\'work_id\\': \\'W024\\'}\"}]}}\n",
            "Tool #2: find_resources_tool\n",
            "\n",
            "Tool #3: find_resources_tool\n",
            "{\"find_resources_tool_response\": {\"output\": [{\"text\": \"{\\'work_id\\': \\'W024\\', \\'candidates\\': [{\\'resource_id\\': \\'R001\\', \\'name\\': \\'Dr. John Smith\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 178, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 2}, {\\'resource_id\\': \\'R002\\', \\'name\\': \\'Dr. Emily Brown\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 100, \\'available_from\\': Timedelta(\\'0 days 08:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 13:00:00\\'), \\'current_workload\\': 8}, {\\'resource_id\\': \\'R003\\', \\'name\\': \\'Dr. Michael Davis\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 172, \\'available_from\\': Timedelta(\\'0 days 07:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 19:00:00\\'), \\'current_workload\\': 8}, {\\'resource_id\\': \\'R004\\', \\'name\\': \\'Dr. Alex Johnson\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 217, \\'available_from\\': Timedelta(\\'0 days 08:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 13:00:00\\'), \\'current_workload\\': 10}], \\'count\\': 4, \\'timestamp\\': \\'2024-11-11 14:00:00\\'}\"}]}\n",
            "Tool #3: score_candidates_tool\n",
            "\n",
            "Tool #4: score_candidates_tool\n",
            "{\"score_candidates_tool_response\": {\"output\": [{\"text\": \"{\\'work_id\\': \\'W024\\', \\'match_score\\': 92, \\'resource_id\\': \\'R001\\', \\'best_match\\': {\\'resource_id\\': \\'R001\\', \\'name\\': \\'Dr. John Smith\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 178, \\'current_workload\\': 2, \\'total_score\\': 92, \\'role_score\\': 40, \\'skill_score\\': 16, \\'experience_score\\': 15, \\'availability_score\\': 15, \\'workload_score\\': 6, \\'priority_bonus\\': \\'none\\'}, \\'runners_up\\': [{\\'resource_id\\': \\'R003\\', \\'name\\': \\'Dr. Michael Davis\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 172, \\'current_workload\\': 8, \\'total_score\\': 82, \\'role_score\\': 40, \\'skill_score\\': 12, \\'experience_score\\': 15, \\'availability_score\\': 15, \\'workload_score\\': 0, \\'priority_bonus\\': \\'none\\'}, {\\'resource_id\\': \\'R004\\', \\'name\\': \\'Dr. Alex Johnson\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 217, \\'current_workload\\': 10, \\'total_score\\': 76, \\'role_score\\': 40, \\'skill_score\\': 16, \\'experience_score\\': 15, \\'availability_score\\': 5, \\'workload_score\\': 0, \\'priority_bonus\\': \\'none\\'}], \\'scoring_logic\\': {\\'total\\': 100, \\'breakdown\\': {\\'role_match\\': \\'40/40\\', \\'skill\\': \\'16/20\\', \\'experience\\': \\'15/15\\', \\'availability\\': \\'15/15\\', \\'workload\\': \\'6/10\\'}, \\'priority_bonus\\': \\'none\\'}}\"}]}\n",
            "Tool #3: assign_work_tool\n",
            "\n",
            "Tool #4: log_assignment_tool\n",
            "Assignment Status: {'status': 'success', 'work_id': 'W024', 'resource_id': 'R001', 'message': 'Successfully assigned W024 to R001', 'match_score': 92.0}\n",
            "\n",
            "--- Execution Result ---\n",
            "Status: Status.COMPLETED\n",
            "\n",
            "--- Assignment Log ---\n",
            " log_id work_id resource_id assignment_timestamp  match_score                                                                                                                                                                                                                                                                      reasoning\n",
            "      2    W024        R001  2025-11-19 18:43:13         92.0 Dr. John Smith (R001) is the best match for work W024 with a score of 92, driven by a perfect role match as a General Radiologist, high skill level, and extensive experience. His good availability and manageable current workload further solidify this optimal assignment.\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Scenario 2 - Routine Ultrasound_Abdomen (Priority 2)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCENARIO 2: Routine Ultrasound_Abdomen - General Imaging Specialist\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scenario2_input = {\n",
        "    \"work_type\": \"Ultrasound_Abdomen\",\n",
        "    \"description\": \"Kidney stone suspected, routine ultrasound required\",\n",
        "    \"priority\": 2,\n",
        "    \"timestamp\": \"2024-11-11 14:00:00\"\n",
        "}\n",
        "\n",
        "result2 = work_allocation_graph(json.dumps(scenario2_input))\n",
        "\n",
        "print(\"\\n--- Execution Result ---\")\n",
        "print(f\"Status: {result2.status}\")\n",
        "\n",
        "log_df = run_sql(\"SELECT * FROM assignment_log ORDER BY log_id DESC LIMIT 1\")\n",
        "print(\"\\n--- Assignment Log ---\")\n",
        "print(log_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SCENARIO 3: Specialized X_Ray_Bone - Joint pain evaluation\n",
            "================================================================================\n",
            "\n",
            "Tool #3: add_work_tool\n",
            "{\"work_id\": \"W025\", \"status\": \"success\"}\n",
            "Tool #3: analyze_work_tool\n",
            "{\"analyze_work_tool_response\": {\"output\": [{\"text\": \"{\\'required_specialty\\': \\'Musculoskeletal_Specialist\\', \\'alternate_specialty\\': \\'General_Radiologist\\', \\'priority\\': 3, \\'work_type\\': \\'X_Ray_Bone\\', \\'work_id\\': \\'W025\\'}\"}]}}\n",
            "Tool #4: find_resources_tool\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unclosed client session\n",
            "client_session: <aiohttp.client.ClientSession object at 0x000002196AF29810>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"find_resources_tool_response\": {\"output\": [{\"text\": \"{\\'work_id\\': \\'W025\\', \\'candidates\\': [{\\'resource_id\\': \\'R001\\', \\'name\\': \\'Dr. John Smith\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 178, \\'available_from\\': Timedelta(\\'0 days 08:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 13:00:00\\'), \\'current_workload\\': 4}, {\\'resource_id\\': \\'R002\\', \\'name\\': \\'Dr. Emily Brown\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 100, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 8}, {\\'resource_id\\': \\'R003\\', \\'name\\': \\'Dr. Michael Davis\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 3, \\'total_cases_handled\\': 172, \\'available_from\\': Timedelta(\\'0 days 13:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 18:00:00\\'), \\'current_workload\\': 3}, {\\'resource_id\\': \\'R004\\', \\'name\\': \\'Dr. Alex Johnson\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 217, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 4}, {\\'resource_id\\': \\'R012\\', \\'name\\': \\'Dr. David Lee\\', \\'specialty\\': \\'Musculoskeletal_Specialist\\', \\'skill_level\\': 5, \\'total_cases_handled\\': 385, \\'available_from\\': Timedelta(\\'0 days 09:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 17:00:00\\'), \\'current_workload\\': 2}, {\\'resource_id\\': \\'R013\\', \\'name\\': \\'Dr. Jennifer Martinez\\', \\'specialty\\': \\'Musculoskeletal_Specialist\\', \\'skill_level\\': 1, \\'total_cases_handled\\': 61, \\'available_from\\': Timedelta(\\'0 days 08:00:00\\'), \\'available_to\\': Timedelta(\\'0 days 13:00:00\\'), \\'current_workload\\': 7}], \\'count\\': 6, \\'timestamp\\': \\'2024-11-12 08:15:00\\'}\"}]}\n",
            "Tool #5: score_candidates_tool\n",
            "\n",
            "Tool #6: score_candidates_tool\n",
            "{\"score_candidates_tool_response\": {\"output\": [{\"text\": \"{\\'work_id\\': \\'W025\\', \\'match_score\\': 86, \\'resource_id\\': \\'R012\\', \\'best_match\\': {\\'resource_id\\': \\'R012\\', \\'name\\': \\'Dr. David Lee\\', \\'specialty\\': \\'Musculoskeletal_Specialist\\', \\'skill_level\\': 5, \\'total_cases_handled\\': 385, \\'current_workload\\': 2, \\'total_score\\': 86, \\'role_score\\': 40, \\'skill_score\\': 20, \\'experience_score\\': 15, \\'availability_score\\': 5, \\'workload_score\\': 6, \\'priority_bonus\\': \\'none\\'}, \\'runners_up\\': [{\\'resource_id\\': \\'R001\\', \\'name\\': \\'Dr. John Smith\\', \\'specialty\\': \\'General_Radiologist\\', \\'skill_level\\': 4, \\'total_cases_handled\\': 178, \\'current_workload\\': 4, \\'total_score\\': 68, \\'role_score\\': 20, \\'skill_score\\': 16, \\'experience_score\\': 15, \\'availability_score\\': 15, \\'workload_score\\': 2, \\'priority_bonus\\': \\'none\\'}, {\\'resource_id\\': \\'R013\\', \\'name\\': \\'Dr. Jennifer Martinez\\', \\'specialty\\': \\'Musculoskeletal_Specialist\\', \\'skill_level\\': 1, \\'total_cases_handled\\': 61, \\'current_workload\\': 7, \\'total_score\\': 65.1, \\'role_score\\': 40, \\'skill_score\\': 4, \\'experience_score\\': 6.1, \\'availability_score\\': 15, \\'workload_score\\': 0, \\'priority_bonus\\': \\'none\\'}], \\'scoring_logic\\': {\\'total\\': 100, \\'breakdown\\': {\\'role_match\\': \\'40/40\\', \\'skill\\': \\'20/20\\', \\'experience\\': \\'15/15\\', \\'availability\\': \\'5/15\\', \\'workload\\': \\'6/10\\'}, \\'priority_bonus\\': \\'none\\'}}\"}]}\n",
            "Tool #5: assign_work_tool\n",
            "\n",
            "Tool #6: log_assignment_tool\n",
            "Assignment Status: {'status': 'success', 'work_id': 'W025', 'resource_id': 'R012', 'message': 'Successfully assigned W025 to R012', 'match_score': 86.0}\n",
            "\n",
            "--- Execution Result ---\n",
            "Status: Status.COMPLETED\n",
            "\n",
            "--- Assignment Log ---\n",
            " log_id work_id resource_id assignment_timestamp  match_score                                                                                                                                                                                                                                                                                                                                              reasoning\n",
            "      3    W025        R012  2025-11-19 18:44:06         86.0 Dr. David Lee (R012) is the best match for work W025 with a score of 86, largely due to his perfect role match as a Musculoskeletal Specialist, high skill level, and extensive experience. Although his availability score is lower, his strong performance in other critical areas makes him the most suitable candidate for this specialized x-ray.\n"
          ]
        }
      ],
      "source": [
        "# Cell 11: Scenario 3 - Specialized X_Ray_Bone (Priority 3)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCENARIO 3: Specialized X_Ray_Bone - Joint pain evaluation\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "scenario3_input = {\n",
        "    \"work_type\": \"X_Ray_Bone\",\n",
        "    \"description\": \"Specialized x-ray for joint pain evaluation\",\n",
        "    \"priority\": 3,\n",
        "    \"timestamp\": \"2024-11-12 08:15:00\"\n",
        "}\n",
        "\n",
        "result3 = work_allocation_graph(json.dumps(scenario3_input))\n",
        "\n",
        "print(\"\\n--- Execution Result ---\")\n",
        "print(f\"Status: {result3.status}\")\n",
        "\n",
        "log_df = run_sql(\"SELECT * FROM assignment_log ORDER BY log_id DESC LIMIT 1\")\n",
        "print(\"\\n--- Assignment Log ---\")\n",
        "print(log_df.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "GenAI Internship Assignment",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
